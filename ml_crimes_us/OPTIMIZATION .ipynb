{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e71bed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE,SMOTENC\n",
    "from imblearn.under_sampling import NearMiss,RandomUnderSampler\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, RandomizedSearchCV, learning_curve\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, OneHotEncoder,StandardScaler\n",
    "from feature_engine.encoding import CountFrequencyEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score, roc_auc_score, log_loss\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "462bf301",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_folder = r'C:\\Users\\eduar\\OneDrive\\√Årea de Trabalho\\EXPERIMENTOS DATA SCIENCE E GIS\\CASE KG\\infolder\\optimization'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "875cabe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'PROSTITUTION'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d47d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(os.path.join(in_folder,\"X_train.csv\"))\n",
    "X_test = pd.read_csv(os.path.join(in_folder,\"X_test.csv\"))\n",
    "y_train = pd.read_csv(os.path.join(in_folder,\"y_train.csv\"))\n",
    "y_test = pd.read_csv(os.path.join(in_folder,\"y_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61df190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropar_coluna(df):\n",
    "    lista_drop = [x for x in df.columns if x not in cat_cols and x not in num_cols]\n",
    "    df.drop(lista_drop,axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c5e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"DayOfWeek\",\"AV\",\"Block\",\"crossing\",\"PdDistrict\",\"ST\",\"cluster\",\"night_time\",'late_night', 'evening']\n",
    "num_cols = [\"X\",\"Y\",'dist_police',\"Month\",\"Year\",\"hour\",'dist_bar','dist_nightclub']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9bd793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropar_coluna(X_train)\n",
    "dropar_coluna(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "434bc472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformers\n",
    "pipe_cat_features = (\n",
    "    'onehot_encoder',\n",
    "    OneHotEncoder(handle_unknown='ignore'),\n",
    "    cat_cols\n",
    ")\n",
    "\n",
    "\n",
    "pipe_num_features = (\n",
    "    'MinMaxScaler',\n",
    "    MinMaxScaler(),\n",
    "    num_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e11d9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the transformers list\n",
    "transformers = [pipe_cat_features, pipe_num_features]\n",
    "pipe_transformers = ColumnTransformer(transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b522c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "over = SMOTE(random_state=123,n_jobs = 6,sampling_strategy=0.15)\n",
    "under = RandomUnderSampler(sampling_strategy=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "246cb070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'model__min_child_weight': [1, 5, 10],\n",
    "        'model__gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'model__subsample': [0.6, 0.8, 1.0],\n",
    "        'model__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'model__max_depth': [3, 4, 5,6,7,8,9,10,11],\n",
    "        'model__eta' : [0.02,0.15,0.2]\n",
    "        \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a1f415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "pipeline = Pipeline(steps=[('pre_processor', pipe_transformers),('o', over),(\"u\",under),('model', XGBClassifier(**params))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0517434",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(predictor = \"gpu_predictor\",tree_method=\"gpu_hist\", n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5287059c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\.conda\\envs\\exp\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\eduar\\.conda\\envs\\exp\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\eduar\\.conda\\envs\\exp\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:17:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"model__colsample_bytree\", \"model__eta\", \"model__gamma\", \"model__max_depth\", \"model__min_child_weight\", \"model__subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:17:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x000002582C0CAAC0>,\n",
       "                   estimator=Pipeline(steps=[('pre_processor',\n",
       "                                              ColumnTransformer(transformers=[('onehot_encoder',\n",
       "                                                                               OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                                               ['DayOfWeek',\n",
       "                                                                                'AV',\n",
       "                                                                                'Block',\n",
       "                                                                                'crossing',\n",
       "                                                                                'PdDistrict',\n",
       "                                                                                'ST',\n",
       "                                                                                'cluster',\n",
       "                                                                                'night_time',\n",
       "                                                                                'late_night',\n",
       "                                                                                'evening']),\n",
       "                                                                              ('MinMaxScaler',\n",
       "                                                                               MinMaxScaler(),\n",
       "                                                                               ['X',\n",
       "                                                                                'Y'...\n",
       "                                                            reg_alpha=None,\n",
       "                                                            reg_lambda=None,\n",
       "                                                            scale_pos_weight=None, ...))]),\n",
       "                   n_iter=200, n_jobs=6,\n",
       "                   param_distributions={'model__colsample_bytree': [0.6, 0.8,\n",
       "                                                                    1.0],\n",
       "                                        'model__eta': [0.02, 0.15, 0.2],\n",
       "                                        'model__gamma': [0.5, 1, 1.5, 2, 5],\n",
       "                                        'model__max_depth': [3, 4, 5, 6, 7, 8,\n",
       "                                                             9, 10, 11],\n",
       "                                        'model__min_child_weight': [1, 5, 10],\n",
       "                                        'model__subsample': [0.6, 0.8, 1.0]},\n",
       "                   random_state=123, scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = 5\n",
    "param_comb = 200\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 123)\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=params, n_iter=param_comb,\n",
    "                                   scoring='f1', n_jobs=6, cv=skf.split(X_train,y_train),\n",
    "                                   verbose=1, random_state=123 )\n",
    "\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea66e9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pre_processor',\n",
      "                 ColumnTransformer(transformers=[('onehot_encoder',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['DayOfWeek', 'AV', 'Block',\n",
      "                                                   'crossing', 'PdDistrict',\n",
      "                                                   'ST', 'cluster',\n",
      "                                                   'night_time', 'late_night',\n",
      "                                                   'evening']),\n",
      "                                                 ('MinMaxScaler',\n",
      "                                                  MinMaxScaler(),\n",
      "                                                  ['X', 'Y', 'dist_police',\n",
      "                                                   'Month', 'Year', 'hour',\n",
      "                                                   'dist_bar',\n",
      "                                                   'dist_nightclub'])])),\n",
      "                ('o',\n",
      "                 SMOTE(n_job...\n",
      "                               max_depth=10, min_child_weight=5, missing=nan,\n",
      "                               model__colsample_bytree=[0.6, 0.8, 1.0],\n",
      "                               model__eta=[0.02, 0.15, 0.2],\n",
      "                               model__gamma=[0.5, 1, 1.5, 2, 5],\n",
      "                               model__max_depth=[3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
      "                               model__min_child_weight=[1, 5, 10],\n",
      "                               model__subsample=[0.6, 0.8, 1.0],\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=16, num_parallel_tree=1, predictor='auto',\n",
      "                               random_state=0, reg_alpha=0, reg_lambda=1, ...))])\n"
     ]
    }
   ],
   "source": [
    "print(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef4c7f5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6630795271184154\n"
     ]
    }
   ],
   "source": [
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3398fc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__subsample': 1.0, 'model__min_child_weight': 5, 'model__max_depth': 10, 'model__gamma': 2, 'model__eta': 0.2, 'model__colsample_bytree': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ee897ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\.conda\\envs\\exp\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\eduar\\.conda\\envs\\exp\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\eduar\\.conda\\envs\\exp\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9925982403363819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    262262\n",
      "         1.0       0.62      0.67      0.65      2675\n",
      "\n",
      "    accuracy                           0.99    264937\n",
      "   macro avg       0.81      0.83      0.82    264937\n",
      "weighted avg       0.99      0.99      0.99    264937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "over = SMOTE(random_state=123,n_jobs = 6,sampling_strategy=0.15)\n",
    "under = RandomUnderSampler(sampling_strategy=0.15)\n",
    "\n",
    "\n",
    "#Creating a single pipeline with XGboost classifier\n",
    "parametros_otimizados = {\n",
    " 'tree_method': 'gpu_hist',\n",
    " 'predictor': 'gpu_predictor',\n",
    " 'max_depth': 11,\n",
    " 'eta': 0.2,\n",
    " 'objective': 'binary:logistic',\n",
    " 'min_child_weight': 5,\n",
    " 'random_state': 123,'gamma': 1,'colsample_bytree': 1.0,'subsample': 0.8,\n",
    " 'eval_metric': 'auc','sampling_method': 'gradient_based','booster': 'dart'}\n",
    "\n",
    "#pipe_xg = create_pipe(XGBClassifier(**parametros_otimizados), pipe_transformers)\n",
    "pipe = Pipeline(steps=[('pre_processor', pipe_transformers),('o', over),(\"u\",under),('model', XGBClassifier(**parametros_otimizados))])\n",
    "\n",
    "xgb_clf = pipe \n",
    "xgb_clf.fit(X_train, y_train)\n",
    "score = xgb_clf.score(X_test, y_test)\n",
    "print(score)\n",
    "\n",
    "#Predicting the test dataset\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "#Print the classification report\n",
    "results_log = classification_report(y_test, y_pred)\n",
    "print(results_log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
